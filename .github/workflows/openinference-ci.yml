name: OpenInference Integration CI/CD

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'src/utils/openinference_tracer.py'
      - 'src/core/engines/enhanced_bayesian_engine.py'
      - 'src/api/v1/routes/enhanced_analysis.py'
      - 'tests/**/*openinference*'
      - 'requirements.txt'
      - '.github/workflows/openinference-ci.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'src/utils/openinference_tracer.py'
      - 'src/core/engines/enhanced_bayesian_engine.py'
      - 'src/api/v1/routes/enhanced_analysis.py'
      - 'tests/**/*openinference*'
      - 'requirements.txt'

env:
  PYTHON_VERSION: "3.11"
  ENVIRONMENT: "testing"
  LOG_LEVEL: "CRITICAL"

jobs:
  dependency-check:
    name: Dependency Security Check
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install safety bandit semgrep
        pip install -r requirements.txt
    
    - name: Run safety check
      run: safety check --json --output safety-report.json || true
    
    - name: Run bandit security check
      run: bandit -r src/ -f json -o bandit-report.json || true
    
    - name: Upload security reports
      uses: actions/upload-artifact@v3
      with:
        name: security-reports
        path: |
          safety-report.json
          bandit-report.json

  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: dependency-check
    strategy:
      matrix:
        python-version: ["3.9", "3.10", "3.11", "3.12"]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-mock pytest-timeout
    
    - name: Run unit tests
      run: |
        pytest tests/unit/test_openinference_tracer.py \
               tests/unit/test_enhanced_bayesian_engine.py \
               --cov=src/utils/openinference_tracer \
               --cov=src/core/engines/enhanced_bayesian_engine \
               --cov-report=xml \
               --cov-report=html \
               --junit-xml=junit-unit-${{ matrix.python-version }}.xml \
               -v
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unit-tests
        name: codecov-umbrella
    
    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-results-unit-${{ matrix.python-version }}
        path: |
          junit-unit-${{ matrix.python-version }}.xml
          htmlcov/

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    services:
      jaeger:
        image: jaegertracing/all-in-one:latest
        ports:
          - 16686:16686
          - 6831:6831/udp
        env:
          COLLECTOR_OTLP_ENABLED: true
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-timeout
    
    - name: Wait for Jaeger
      run: |
        timeout 60 bash -c 'until curl -f http://localhost:16686/api/services; do sleep 2; done'
    
    - name: Run integration tests
      env:
        OTEL_TRACING_ENABLED: "true"
        JAEGER_ENDPOINT: "localhost:6831"
        OTEL_CONSOLE_EXPORTER: "false"
      run: |
        pytest tests/integration/test_openinference_integration.py \
               --cov=src \
               --cov-report=xml \
               --junit-xml=junit-integration.xml \
               --timeout=300 \
               -v -s
    
    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-results-integration
        path: |
          junit-integration.xml
          coverage.xml

  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: integration-tests
    services:
      phoenix:
        image: arizephoenix/phoenix:latest
        ports:
          - 6006:6006
        options: --health-cmd="curl -f http://localhost:6006/healthz" --health-interval=10s --health-timeout=5s --health-retries=5
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-timeout
    
    - name: Wait for Phoenix
      run: |
        timeout 60 bash -c 'until curl -f http://localhost:6006/healthz; do sleep 2; done'
    
    - name: Run E2E tests
      env:
        OTEL_TRACING_ENABLED: "true"
        PHOENIX_ENDPOINT: "http://localhost:6006"
        OTEL_CONSOLE_EXPORTER: "false"
      run: |
        pytest tests/e2e/test_openinference_e2e.py \
               --junit-xml=junit-e2e.xml \
               --timeout=600 \
               -v -s
    
    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-results-e2e
        path: junit-e2e.xml

  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: integration-tests
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-benchmark
    
    - name: Run performance tests
      run: |
        pytest tests/performance/test_openinference_performance.py \
               --junit-xml=junit-performance.xml \
               --benchmark-json=benchmark-results.json \
               -v -s
    
    - name: Upload performance results
      uses: actions/upload-artifact@v3
      with:
        name: performance-results
        path: |
          junit-performance.xml
          benchmark-results.json

  demo-validation:
    name: Demo Script Validation
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Validate demo script
      env:
        OTEL_TRACING_ENABLED: "false"  # Disable tracing for demo validation
      run: |
        timeout 120 python scripts/demo/openinference_demo.py || true
        # Check if demo ran without critical errors
        if [ $? -eq 124 ]; then
          echo "Demo script validation completed (timeout expected)"
        else
          echo "Demo script validation failed"
          exit 1
        fi

  code-quality:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install black flake8 mypy pylint isort
        pip install -r requirements.txt
    
    - name: Run black code formatting check
      run: black --check --diff src/utils/openinference_tracer.py src/core/engines/enhanced_bayesian_engine.py
    
    - name: Run flake8 linting
      run: flake8 src/utils/openinference_tracer.py src/core/engines/enhanced_bayesian_engine.py --max-line-length=120
    
    - name: Run isort import sorting check
      run: isort --check-only --diff src/utils/openinference_tracer.py src/core/engines/enhanced_bayesian_engine.py
    
    - name: Run mypy type checking
      run: mypy src/utils/openinference_tracer.py --ignore-missing-imports || true
    
    - name: Run pylint
      run: pylint src/utils/openinference_tracer.py --disable=C0103,R0903 || true

  documentation-check:
    name: Documentation Check
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Check documentation files exist
      run: |
        test -f docs/OPENINFERENCE_INTEGRATION.md
        test -f OPENINFERENCE_INTEGRATION_SUMMARY.md
        test -f config/openinference_config.json
    
    - name: Validate JSON configuration
      run: |
        python -c "import json; json.load(open('config/openinference_config.json'))"
    
    - name: Check README updates
      run: |
        grep -q "openinference" requirements.txt
        echo "Documentation validation completed"

  deployment-readiness:
    name: Deployment Readiness Check
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, e2e-tests, code-quality]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Test production configuration
      env:
        ENVIRONMENT: "production"
        OTEL_TRACING_ENABLED: "true"
        OTEL_CONSOLE_EXPORTER: "false"
        OTEL_SAMPLING_RATE: "0.1"
      run: |
        python -c "
        import sys
        sys.path.insert(0, 'src')
        from utils.openinference_tracer import initialize_tracing
        config = {
            'enabled': True,
            'console_exporter': False,
            'sampling_rate': 0.1
        }
        initialize_tracing(config)
        print('Production configuration validated')
        "
    
    - name: Create deployment artifact
      run: |
        tar -czf openinference-integration.tar.gz \
          src/utils/openinference_tracer.py \
          src/core/engines/enhanced_bayesian_engine.py \
          src/api/v1/routes/enhanced_analysis.py \
          config/openinference_config.json \
          docs/OPENINFERENCE_INTEGRATION.md \
          requirements.txt
    
    - name: Upload deployment artifact
      uses: actions/upload-artifact@v3
      with:
        name: openinference-integration
        path: openinference-integration.tar.gz

  notify-completion:
    name: Notify CI/CD Completion
    runs-on: ubuntu-latest
    needs: [deployment-readiness, performance-tests, demo-validation]
    if: always()
    
    steps:
    - name: Check overall status
      run: |
        if [ "${{ needs.deployment-readiness.result }}" = "success" ]; then
          echo "✅ OpenInference integration CI/CD completed successfully"
          echo "🚀 Ready for production deployment"
        else
          echo "❌ OpenInference integration CI/CD failed"
          echo "🔧 Check failed jobs for details"
          exit 1
        fi
