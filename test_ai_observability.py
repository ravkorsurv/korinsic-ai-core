#!/usr/bin/env python3
"""
Test script for Korinsic AI Observability with OpenInference

This script demonstrates the OpenInference integration by running a sample
analysis and showing the telemetry data being generated.
"""

import os
import sys
import json
import time
from datetime import datetime

# Add src to path
sys.path.append('src')

from utils.ai_observability import initialize_ai_observability
from core.bayesian_engine import BayesianEngine

def create_sample_data():
    """Create sample trading data for testing"""
    return {
        'trader_info': {
            'trader_id': 'TRADER_001',
            'access_level': 'high',
            'department': 'equity_trading'
        },
        'trades': [
            {
                'trade_id': 'T001',
                'instrument': 'AAPL',
                'quantity': 10000,
                'price': 150.25,
                'timestamp': datetime.now().isoformat()
            }
        ],
        'market_data': {
            'volatility': 0.25,
            'price_movement': 0.12,
            'volume': 50000
        },
        'communications': [
            {
                'content': 'We should consider sensitive information in our trades',
                'timestamp': datetime.now().isoformat()
            }
        ],
        'pnl_data': {
            'daily_loss': -150000,
            'unusual_pattern': True
        }
    }

def test_ai_observability():
    """Test AI observability with sample data"""
    print("ğŸš€ Testing Korinsic AI Observability with OpenInference")
    print("=" * 60)
    
    # Initialize AI observability
    print("1. Initializing AI observability...")
    ai_obs = initialize_ai_observability(
        service_name="korinsic-ai-test",
        service_version="1.0.0-test",
        otlp_endpoint=os.getenv("OTEL_EXPORTER_OTLP_ENDPOINT", "http://localhost:4317")
    )
    print(f"   âœ… AI observability initialized")
    print(f"   ğŸ“¡ OTLP Endpoint: {ai_obs.otlp_endpoint}")
    
    # Initialize Bayesian engine
    print("\n2. Initializing Bayesian engine...")
    try:
        bayesian_engine = BayesianEngine()
        print(f"   âœ… Bayesian engine loaded successfully")
        models_info = bayesian_engine.get_models_info()
        print(f"   ğŸ“Š Models loaded: {models_info.get('models_loaded', False)}")
    except Exception as e:
        print(f"   âŒ Error loading Bayesian engine: {e}")
        return False
    
    # Create sample data
    print("\n3. Creating sample trading data...")
    sample_data = create_sample_data()
    print(f"   âœ… Sample data created")
    print(f"   ğŸ‘¤ Trader ID: {sample_data['trader_info']['trader_id']}")
    print(f"   ğŸ“ˆ Trades: {len(sample_data['trades'])}")
    print(f"   ğŸ’° Daily Loss: ${abs(sample_data['pnl_data']['daily_loss']):,}")
    
    # Run analysis with tracing
    print("\n4. Running AI analysis with OpenInference tracing...")
    start_time = time.time()
    
    try:
        # This will automatically use the OpenInference tracing we added
        result = bayesian_engine.analyze_insider_dealing(sample_data)
        
        analysis_time = (time.time() - start_time) * 1000
        
        print(f"   âœ… Analysis completed in {analysis_time:.2f}ms")
        print(f"   ğŸ¯ Risk Score: {result.get('risk_score', 0.0):.3f}")
        print(f"   ğŸ“Š ESI Score: {result.get('esi_score', 0.0):.3f}")
        print(f"   ğŸ”§ Fallback Usage: {len([k for k, v in result.get('fallback_usage', {}).items() if v])}")
        
        # Show trace information
        print(f"\n5. Trace Information:")
        print(f"   ğŸ” Model Type: {result.get('model_type', 'unknown')}")
        print(f"   ï¿½ï¿½ Evidence Used: {len(result.get('evidence_used', {}))}")
        print(f"   âš¡ Performance: {analysis_time:.2f}ms")
        
        return True
        
    except Exception as e:
        print(f"   âŒ Error during analysis: {e}")
        return False

def main():
    """Main test function"""
    print("Korinsic AI Observability Test")
    print("Testing OpenInference integration with Bayesian models")
    print()
    
    success = test_ai_observability()
    
    print("\n" + "=" * 60)
    if success:
        print("âœ… Test completed successfully!")
        print()
        print("ğŸ‰ What just happened:")
        print("   â€¢ OpenInference tracing was initialized")
        print("   â€¢ Bayesian inference was traced with AI-specific attributes")
        print("   â€¢ Evidence mapping and fallback usage were recorded")
        print("   â€¢ Performance metrics were captured")
        print("   â€¢ All telemetry was sent to your OTLP endpoint")
        print()
        print("ğŸ” Next Steps:")
        print("   â€¢ Check your observability dashboard for traces")
        print("   â€¢ Look for spans with names like 'bayesian_inference.insider_dealing'")
        print("   â€¢ Examine AI-specific attributes like 'ai.risk.score' and 'ai.evidence.count'")
        print("   â€¢ Monitor fallback usage and inference latency")
    else:
        print("âŒ Test failed - check the errors above")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
